{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW_9.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Языковое моделирование\n",
        "Задание\n",
        "Разобраться с моделькой генерации текста, собрать самим или взять датасет с вебинара и обучить генератор текстов"
      ],
      "metadata": {
        "id": "92zq5wBSkeUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from keras.callbacks import EarlyStopping\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "rEx43pbKs25A"
      },
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#загружаем файл\n",
        "text = open('/KAK_Ya_VSTRETIL_VAShU_MAMU_1.txt', 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "# Определяем длину текста (количество букв в нем)\n",
        "print('Length of text: {} characters'.format(len(text)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SMsFpXsTs3b6",
        "outputId": "67420ca9-f920-4e72-dd56-0af57f10503b"
      },
      "execution_count": 294,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 56360 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#просматриваем фрагмент текста\n",
        "print(text[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0CwA-dC0s8Yp",
        "outputId": "244ef7dc-b365-47a2-c5e5-1f5285d3c840"
      },
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "АКТ ПЕРВЫЙ\r\n",
            "ИНТ. 2029 ГОСТИНАЯ - ВЕЧЕР\r\n",
            "РАССКАЗЧИК, ДОЧЬ, СЫН\r\n",
            "Уютный диван в гостиной некоего пригородного дома. В камине\r\n",
            "потрескивает огонь. Двое подростков - 14-летний СЫН и 16-\r\n",
            "летняя ДОЧЬ - сидят на диване. Они глядят в камеру и слушают\r\n",
            "РАССКАЗЧИКА.\r\n",
            "                      РАССКАЗЧИК (З.К.)\r\n",
            "             Ладно, ребятки, вы уже достаточно\r\n",
            "             взрослые, и я собираюсь рассказать\r\n",
            "             вам о том, как я встретил вашу\r\n",
            "             маму.\r\n",
            "                       ДОЧЬ\r\n",
            "         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = text + text + text"
      ],
      "metadata": {
        "id": "gfbPsDFbs9a7"
      },
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# уникальные буквы в файле\n",
        "vocab = sorted(set(text))\n",
        "print('{} unique characters'.format(len(vocab)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4SBb-bztGMS",
        "outputId": "acd1f93e-0da7-4b84-afef-1bd315f30069"
      },
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "91 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#словарь из букв\n",
        "vocab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sG7dGkxdtHm4",
        "outputId": "a35ff00e-294c-410c-9b41-df61478bafb8"
      },
      "execution_count": 298,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\\n',\n",
              " '\\r',\n",
              " ' ',\n",
              " '!',\n",
              " '(',\n",
              " ')',\n",
              " ',',\n",
              " '-',\n",
              " '.',\n",
              " '/',\n",
              " '0',\n",
              " '1',\n",
              " '2',\n",
              " '3',\n",
              " '4',\n",
              " '5',\n",
              " '6',\n",
              " '7',\n",
              " '8',\n",
              " '9',\n",
              " ':',\n",
              " ';',\n",
              " '?',\n",
              " '«',\n",
              " '»',\n",
              " 'А',\n",
              " 'Б',\n",
              " 'В',\n",
              " 'Г',\n",
              " 'Д',\n",
              " 'Е',\n",
              " 'Ж',\n",
              " 'З',\n",
              " 'И',\n",
              " 'Й',\n",
              " 'К',\n",
              " 'Л',\n",
              " 'М',\n",
              " 'Н',\n",
              " 'О',\n",
              " 'П',\n",
              " 'Р',\n",
              " 'С',\n",
              " 'Т',\n",
              " 'У',\n",
              " 'Ф',\n",
              " 'Х',\n",
              " 'Ц',\n",
              " 'Ч',\n",
              " 'Ш',\n",
              " 'Щ',\n",
              " 'Ы',\n",
              " 'Ь',\n",
              " 'Э',\n",
              " 'Ю',\n",
              " 'Я',\n",
              " 'а',\n",
              " 'б',\n",
              " 'в',\n",
              " 'г',\n",
              " 'д',\n",
              " 'е',\n",
              " 'ж',\n",
              " 'з',\n",
              " 'и',\n",
              " 'й',\n",
              " 'к',\n",
              " 'л',\n",
              " 'м',\n",
              " 'н',\n",
              " 'о',\n",
              " 'п',\n",
              " 'р',\n",
              " 'с',\n",
              " 'т',\n",
              " 'у',\n",
              " 'ф',\n",
              " 'х',\n",
              " 'ц',\n",
              " 'ч',\n",
              " 'ш',\n",
              " 'щ',\n",
              " 'ъ',\n",
              " 'ы',\n",
              " 'ь',\n",
              " 'э',\n",
              " 'ю',\n",
              " 'я',\n",
              " '–',\n",
              " '…',\n",
              " '№']"
            ]
          },
          "metadata": {},
          "execution_count": 298
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Задаем отображения из множества уникальных букв в множество индексов\n",
        "char2idx = {u:i for i, u in enumerate(vocab)}  #{уникальная буквы : ее индекс из словаря}\n",
        "\n",
        "# Представление текста в виде последовательности чисел (индексы букв из словаря)\n",
        "idx2char = np.array(vocab) # список из символов словаря (можно по индексу извлекать букву)\n",
        "text_as_int = np.array([char2idx[c] for c in text])"
      ],
      "metadata": {
        "id": "2qU43I9-tKGB"
      },
      "execution_count": 299,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:500]), print(text_as_int[:500])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eR4qS3gltMMa",
        "outputId": "ffc8007d-314a-4470-ff97-e32436e23c66"
      },
      "execution_count": 300,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "АКТ ПЕРВЫЙ\r\n",
            "ИНТ. 2029 ГОСТИНАЯ - ВЕЧЕР\r\n",
            "РАССКАЗЧИК, ДОЧЬ, СЫН\r\n",
            "Уютный диван в гостиной некоего пригородного дома. В камине\r\n",
            "потрескивает огонь. Двое подростков - 14-летний СЫН и 16-\r\n",
            "летняя ДОЧЬ - сидят на диване. Они глядят в камеру и слушают\r\n",
            "РАССКАЗЧИКА.\r\n",
            "                      РАССКАЗЧИК (З.К.)\r\n",
            "             Ладно, ребятки, вы уже достаточно\r\n",
            "             взрослые, и я собираюсь рассказать\r\n",
            "             вам о том, как я встретил вашу\r\n",
            "             маму.\r\n",
            "                       ДОЧЬ\r\n",
            "         \n",
            "[25 35 43  2 40 30 41 27 51 34  1  0 33 38 43  8  2 12 10 12 19  2 28 39\n",
            " 42 43 33 38 25 55  2  7  2 27 30 48 30 41  1  0 41 25 42 42 35 25 32 48\n",
            " 33 35  6  2 29 39 48 52  6  2 42 51 38  1  0 44 86 74 69 83 65  2 60 64\n",
            " 58 56 69  2 58  2 59 70 73 74 64 69 70 65  2 69 61 66 70 61 59 70  2 71\n",
            " 72 64 59 70 72 70 60 69 70 59 70  2 60 70 68 56  8  2 27  2 66 56 68 64\n",
            " 69 61  1  0 71 70 74 72 61 73 66 64 58 56 61 74  2 70 59 70 69 84  8  2\n",
            " 29 58 70 61  2 71 70 60 72 70 73 74 66 70 58  2  7  2 11 14  7 67 61 74\n",
            " 69 64 65  2 42 51 38  2 64  2 11 16  7  1  0 67 61 74 69 87 87  2 29 39\n",
            " 48 52  2  7  2 73 64 60 87 74  2 69 56  2 60 64 58 56 69 61  8  2 39 69\n",
            " 64  2 59 67 87 60 87 74  2 58  2 66 56 68 61 72 75  2 64  2 73 67 75 80\n",
            " 56 86 74  1  0 41 25 42 42 35 25 32 48 33 35 25  8  1  0  2  2  2  2  2\n",
            "  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2 41 25 42 42 35 25 32\n",
            " 48 33 35  2  4 32  8 35  8  5  1  0  2  2  2  2  2  2  2  2  2  2  2  2\n",
            "  2 36 56 60 69 70  6  2 72 61 57 87 74 66 64  6  2 58 83  2 75 62 61  2\n",
            " 60 70 73 74 56 74 70 79 69 70  1  0  2  2  2  2  2  2  2  2  2  2  2  2\n",
            "  2 58 63 72 70 73 67 83 61  6  2 64  2 87  2 73 70 57 64 72 56 86 73 84\n",
            "  2 72 56 73 73 66 56 63 56 74 84  1  0  2  2  2  2  2  2  2  2  2  2  2\n",
            "  2  2 58 56 68  2 70  2 74 70 68  6  2 66 56 66  2 87  2 58 73 74 72 61\n",
            " 74 64 67  2 58 56 80 75  1  0  2  2  2  2  2  2  2  2  2  2  2  2  2 68\n",
            " 56 68 75  8  1  0  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2  2\n",
            "  2  2  2  2  2 29 39 48 52  1  0  2  2  2  2  2  2  2  2  2]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 300
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Максимальная длина предложения для входных данных (в буквах)\n",
        "seq_length = 100\n",
        "\n",
        "#количество эпох\n",
        "examples_per_epoch = len(text)//(seq_length+1)"
      ],
      "metadata": {
        "id": "ZtJE9b3etOno"
      },
      "execution_count": 301,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# создаем датасет из данных\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
        "for element in char_dataset:\n",
        "    print(len(char_dataset))\n",
        "    print(element)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vCRdvSkgtQLM",
        "outputId": "7db2a279-d85a-4bf7-b627-aac53ccfb52f"
      },
      "execution_count": 302,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "169080\n",
            "tf.Tensor(25, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for element in char_dataset:\n",
        "    print(idx2char[element.numpy()])\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdi_5dbltRz2",
        "outputId": "7f68495c-133f-4432-e3ec-02c62e6eec88"
      },
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "А\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#создаем батчи из seq_length+1 элементов\n",
        "sequences = char_dataset.batch(seq_length+1, drop_remainder=True) #drop_remainder удаляет неполный батч (с длиной менее seq_length+1)\n",
        "\n",
        "for item in sequences.take(5):\n",
        "    print(repr(''.join(idx2char[item.numpy()])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mT5xMbFtTZi",
        "outputId": "8b40ee09-ab4f-4257-bdf3-eeff42b2f2ae"
      },
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'АКТ ПЕРВЫЙ\\r\\nИНТ. 2029 ГОСТИНАЯ - ВЕЧЕР\\r\\nРАССКАЗЧИК, ДОЧЬ, СЫН\\r\\nУютный диван в гостиной некоего пригор'\n",
            "'одного дома. В камине\\r\\nпотрескивает огонь. Двое подростков - 14-летний СЫН и 16-\\r\\nлетняя ДОЧЬ - сидят'\n",
            "' на диване. Они глядят в камеру и слушают\\r\\nРАССКАЗЧИКА.\\r\\n                      РАССКАЗЧИК (З.К.)\\r\\n   '\n",
            "'          Ладно, ребятки, вы уже достаточно\\r\\n             взрослые, и я собираюсь рассказать\\r\\n       '\n",
            "'      вам о том, как я встретил вашу\\r\\n             маму.\\r\\n                       ДОЧЬ\\r\\n             О'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Разбиваем каждый батч на признаки и целевую переменную (последнюю букву)\n",
        "def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "#применяем функцию split_input_target ко всем батчам\n",
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "VhvgXJUYtVNB"
      },
      "execution_count": 305,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset:\n",
        "    print(f'Количество батчей: {len(dataset)}')\n",
        "    print(f'Данные: {input_example}')\n",
        "    print(f'Целевая переменная: {target_example}')\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HcrT6S4tXGt",
        "outputId": "a6d49b1c-5266-463a-cf92-090dbd2ba0c3"
      },
      "execution_count": 306,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество батчей: 1674\n",
            "Данные: [25 35 43  2 40 30 41 27 51 34  1  0 33 38 43  8  2 12 10 12 19  2 28 39\n",
            " 42 43 33 38 25 55  2  7  2 27 30 48 30 41  1  0 41 25 42 42 35 25 32 48\n",
            " 33 35  6  2 29 39 48 52  6  2 42 51 38  1  0 44 86 74 69 83 65  2 60 64\n",
            " 58 56 69  2 58  2 59 70 73 74 64 69 70 65  2 69 61 66 70 61 59 70  2 71\n",
            " 72 64 59 70]\n",
            "Целевая переменная: [35 43  2 40 30 41 27 51 34  1  0 33 38 43  8  2 12 10 12 19  2 28 39 42\n",
            " 43 33 38 25 55  2  7  2 27 30 48 30 41  1  0 41 25 42 42 35 25 32 48 33\n",
            " 35  6  2 29 39 48 52  6  2 42 51 38  1  0 44 86 74 69 83 65  2 60 64 58\n",
            " 56 69  2 58  2 59 70 73 74 64 69 70 65  2 69 61 66 70 61 59 70  2 71 72\n",
            " 64 59 70 72]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
        "    print('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXGenA5btaO2",
        "outputId": "826221e5-0aaa-4327-dbb4-e406fa55b713"
      },
      "execution_count": 307,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input data:  'АКТ ПЕРВЫЙ\\r\\nИНТ. 2029 ГОСТИНАЯ - ВЕЧЕР\\r\\nРАССКАЗЧИК, ДОЧЬ, СЫН\\r\\nУютный диван в гостиной некоего приго'\n",
            "Target data: 'КТ ПЕРВЫЙ\\r\\nИНТ. 2029 ГОСТИНАЯ - ВЕЧЕР\\r\\nРАССКАЗЧИК, ДОЧЬ, СЫН\\r\\nУютный диван в гостиной некоего пригор'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# размер батча\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# размер буфера для перемешивания данных\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "# перемешивание разделенных данных\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rcw63pr6tcQC",
        "outputId": "4ff358ef-8ae0-444a-de8a-4e721cdce29f"
      },
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Длина словаря в буквах\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Размерность эмбеддинга\n",
        "embedding_dim = 256\n",
        "\n",
        "# Число ячеек\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "5EGZvkfAteAw"
      },
      "execution_count": 309,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
        "                                  batch_input_shape=[batch_size, None]),\n",
        "                                 \n",
        "        tf.keras.layers.LSTM(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "        tf.keras.layers.LSTM(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "\n",
        "         tf.keras.layers.LSTM(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "        \n",
        "        tf.keras.layers.LSTM(rnn_units,\n",
        "                            return_sequences=True,\n",
        "                            stateful=True,\n",
        "                            recurrent_initializer='glorot_uniform'),\n",
        "                                   \n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "xNzREhwRtgc2"
      },
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = build_model(\n",
        "    vocab_size=len(vocab),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "eXF8zQ7dtiR0"
      },
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc9yNThktkhL",
        "outputId": "89db248c-d877-489f-942e-be938aaa2067"
      },
      "execution_count": 315,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 91) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T3elRX1Ltnr9",
        "outputId": "79d239ff-dec0-4794-88d4-4ba3ea880dac"
      },
      "execution_count": 316,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_19 (Embedding)    (64, None, 256)           23296     \n",
            "                                                                 \n",
            " lstm_69 (LSTM)              (64, None, 1024)          5246976   \n",
            "                                                                 \n",
            " lstm_70 (LSTM)              (64, None, 1024)          8392704   \n",
            "                                                                 \n",
            " lstm_71 (LSTM)              (64, None, 1024)          8392704   \n",
            "                                                                 \n",
            " lstm_72 (LSTM)              (64, None, 1024)          8392704   \n",
            "                                                                 \n",
            " dense_19 (Dense)            (64, None, 91)            93275     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,541,659\n",
            "Trainable params: 30,541,659\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_predictions[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cM0toc6htqC5",
        "outputId": "39f45e48-15fa-4fef-a331-a2ffe0c8072f"
      },
      "execution_count": 317,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(100, 91), dtype=float32, numpy=\n",
              "array([[-1.5729660e-06, -1.4143723e-05,  9.8893797e-06, ...,\n",
              "        -3.1643076e-06,  1.1133703e-05,  1.7663368e-05],\n",
              "       [-9.2694904e-07, -3.5263216e-05,  2.0985739e-05, ...,\n",
              "        -1.0136719e-06,  3.7269318e-05,  5.9394595e-05],\n",
              "       [ 5.4163297e-06, -5.1699772e-05,  5.1134892e-05, ...,\n",
              "        -1.6890990e-06,  7.9410427e-05,  1.2162144e-04],\n",
              "       ...,\n",
              "       [ 2.1410463e-03, -9.5573079e-05, -6.5407564e-04, ...,\n",
              "        -8.0047984e-04,  3.3273671e-03,  1.0984152e-03],\n",
              "       [ 1.9887080e-03,  2.5286339e-05, -7.9202000e-04, ...,\n",
              "        -8.7619666e-04,  3.3234609e-03,  1.1696751e-03],\n",
              "       [ 1.7625657e-03,  9.0853428e-05, -9.2750683e-04, ...,\n",
              "        -9.5121033e-04,  3.2700037e-03,  1.2351001e-03]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 317
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#индексы букв (извлекаем выборки из категориального распределения)\n",
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1) #количество независимых выборок 1\n",
        "\n",
        "#убираем лишнюю размерность (список индексов)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()\n",
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mynniIn7trYR",
        "outputId": "c3545f06-44ad-4aa9-de5c-df520508277c"
      },
      "execution_count": 318,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([56, 75, 24, 28, 25,  7, 82, 10, 39, 33, 62, 18, 64, 38, 39, 25,  1,\n",
              "       58, 57, 46, 26, 63, 59, 30, 39, 23, 82, 81, 15, 61, 46, 55, 73, 71,\n",
              "       27, 27, 42, 71, 64, 10, 71, 42, 26, 29, 57, 13, 50, 68, 71, 75, 74,\n",
              "        0, 69, 78, 49, 90, 71, 25, 18,  2, 21, 77, 33, 51, 85,  4,  2, 75,\n",
              "       49, 77,  8, 74, 47, 56, 88,  1,  2, 60, 70, 81, 11, 21, 30, 78, 59,\n",
              "       19, 86, 21, 36, 29, 24, 75, 67, 18, 37, 36, 71, 47, 58, 60])"
            ]
          },
          "metadata": {},
          "execution_count": 318
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#входной пример\n",
        "#возвращаем строку\n",
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "\n",
        "#предсказанная буква\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l-p1WpUTtuBx",
        "outputId": "808085b5-0ee4-432d-9752-9ef5646f74c0"
      },
      "execution_count": 319,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: \n",
            " 'Маршала и грубо заковывает в наручники.\\r\\nКВАРТИРА РОБИН - НОЧЬ\\r\\nТэд и Робин стоят у двери, прощаясь.'\n",
            "\n",
            "Next Char Predictions: \n",
            " 'ау»ГА-ъ0ОИж8иНОА\\rвбХБзгЕО«ъщ5еХЯспВВСпи0пСБДб3Щмпут\\nнцШ№пА8 ;хИЫэ( уШх.тЦа–\\r дощ1;Ецг9ю;ЛД»ул8МЛпЦвд'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#функция потерь\n",
        "def loss(labels, logits):\n",
        "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
        "\n",
        "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8sC5sxVbtxEA",
        "outputId": "d32d41d8-698a-483c-de0d-d31d8d997028"
      },
      "execution_count": 320,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 91)  # (batch_size, sequence_length, vocab_size)\n",
            "scalar_loss:       4.511663\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#компиляция модели\n",
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "xw1kprPwt0e9"
      },
      "execution_count": 321,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# место для хранения checkpoint\n",
        "checkpoint_dir = '/content/drive/MyDrive/Check'\n",
        "# Имя файла checkpoint\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_freq=88*5,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "jMkEvQR_t27e"
      },
      "execution_count": 322,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#обучение модели\n",
        "EPOCHS = 100\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL2Lb930t7RP",
        "outputId": "09914018-a9e5-40f9-f6ba-66e9bbb989a6"
      },
      "execution_count": 323,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "26/26 [==============================] - 13s 316ms/step - loss: 3.1812\n",
            "Epoch 2/100\n",
            "26/26 [==============================] - 9s 318ms/step - loss: 2.8023\n",
            "Epoch 3/100\n",
            "26/26 [==============================] - 9s 321ms/step - loss: 2.4944\n",
            "Epoch 4/100\n",
            "26/26 [==============================] - 9s 324ms/step - loss: 2.2800\n",
            "Epoch 5/100\n",
            "26/26 [==============================] - 9s 327ms/step - loss: 2.0448\n",
            "Epoch 6/100\n",
            "26/26 [==============================] - 9s 329ms/step - loss: 1.8607\n",
            "Epoch 7/100\n",
            "26/26 [==============================] - 9s 332ms/step - loss: 1.7790\n",
            "Epoch 8/100\n",
            "26/26 [==============================] - 9s 332ms/step - loss: 1.7095\n",
            "Epoch 9/100\n",
            "26/26 [==============================] - 9s 334ms/step - loss: 1.6261\n",
            "Epoch 10/100\n",
            "26/26 [==============================] - 9s 336ms/step - loss: 1.5626\n",
            "Epoch 11/100\n",
            "26/26 [==============================] - 9s 338ms/step - loss: 1.5320\n",
            "Epoch 12/100\n",
            "26/26 [==============================] - 9s 338ms/step - loss: 1.4508\n",
            "Epoch 13/100\n",
            "26/26 [==============================] - 9s 342ms/step - loss: 1.3877\n",
            "Epoch 14/100\n",
            "26/26 [==============================] - 9s 341ms/step - loss: 1.3099\n",
            "Epoch 15/100\n",
            "26/26 [==============================] - 9s 342ms/step - loss: 1.2211\n",
            "Epoch 16/100\n",
            "26/26 [==============================] - 9s 344ms/step - loss: 1.1510\n",
            "Epoch 17/100\n",
            "26/26 [==============================] - 10s 386ms/step - loss: 1.0438\n",
            "Epoch 18/100\n",
            "26/26 [==============================] - 9s 345ms/step - loss: 0.9223\n",
            "Epoch 19/100\n",
            "26/26 [==============================] - 9s 345ms/step - loss: 0.8046\n",
            "Epoch 20/100\n",
            "26/26 [==============================] - 9s 345ms/step - loss: 0.7013\n",
            "Epoch 21/100\n",
            "26/26 [==============================] - 9s 346ms/step - loss: 0.5851\n",
            "Epoch 22/100\n",
            "26/26 [==============================] - 9s 347ms/step - loss: 0.4896\n",
            "Epoch 23/100\n",
            "26/26 [==============================] - 9s 347ms/step - loss: 0.4215\n",
            "Epoch 24/100\n",
            "26/26 [==============================] - 9s 348ms/step - loss: 0.3746\n",
            "Epoch 25/100\n",
            "26/26 [==============================] - 9s 349ms/step - loss: 0.3442\n",
            "Epoch 26/100\n",
            "26/26 [==============================] - 9s 350ms/step - loss: 0.3139\n",
            "Epoch 27/100\n",
            "26/26 [==============================] - 9s 352ms/step - loss: 0.3255\n",
            "Epoch 28/100\n",
            "26/26 [==============================] - 9s 351ms/step - loss: 0.2830\n",
            "Epoch 29/100\n",
            "26/26 [==============================] - 9s 352ms/step - loss: 0.2622\n",
            "Epoch 30/100\n",
            "26/26 [==============================] - 9s 352ms/step - loss: 0.2488\n",
            "Epoch 31/100\n",
            "26/26 [==============================] - 9s 353ms/step - loss: 0.2342\n",
            "Epoch 32/100\n",
            "26/26 [==============================] - 9s 353ms/step - loss: 0.2286\n",
            "Epoch 33/100\n",
            "26/26 [==============================] - 9s 354ms/step - loss: 0.2173\n",
            "Epoch 34/100\n",
            "26/26 [==============================] - 10s 397ms/step - loss: 0.2244\n",
            "Epoch 35/100\n",
            "26/26 [==============================] - 9s 355ms/step - loss: 0.2157\n",
            "Epoch 36/100\n",
            "26/26 [==============================] - 9s 354ms/step - loss: 0.2009\n",
            "Epoch 37/100\n",
            "26/26 [==============================] - 9s 355ms/step - loss: 0.1950\n",
            "Epoch 38/100\n",
            "26/26 [==============================] - 9s 355ms/step - loss: 0.1899\n",
            "Epoch 39/100\n",
            "26/26 [==============================] - 9s 354ms/step - loss: 0.1857\n",
            "Epoch 40/100\n",
            "26/26 [==============================] - 9s 355ms/step - loss: 0.1848\n",
            "Epoch 41/100\n",
            "26/26 [==============================] - 9s 355ms/step - loss: 0.1771\n",
            "Epoch 42/100\n",
            "26/26 [==============================] - 9s 357ms/step - loss: 0.1742\n",
            "Epoch 43/100\n",
            "26/26 [==============================] - 9s 356ms/step - loss: 0.1723\n",
            "Epoch 44/100\n",
            "26/26 [==============================] - 9s 355ms/step - loss: 0.1704\n",
            "Epoch 45/100\n",
            "26/26 [==============================] - 9s 356ms/step - loss: 0.1672\n",
            "Epoch 46/100\n",
            "26/26 [==============================] - 9s 356ms/step - loss: 0.1640\n",
            "Epoch 47/100\n",
            "26/26 [==============================] - 9s 355ms/step - loss: 0.1605\n",
            "Epoch 48/100\n",
            "26/26 [==============================] - 9s 357ms/step - loss: 0.1570\n",
            "Epoch 49/100\n",
            "26/26 [==============================] - 9s 356ms/step - loss: 0.1550\n",
            "Epoch 50/100\n",
            "26/26 [==============================] - 9s 357ms/step - loss: 0.1541\n",
            "Epoch 51/100\n",
            "26/26 [==============================] - 11s 432ms/step - loss: 0.1507\n",
            "Epoch 52/100\n",
            "26/26 [==============================] - 9s 349ms/step - loss: 0.1504\n",
            "Epoch 53/100\n",
            "26/26 [==============================] - 9s 352ms/step - loss: 0.1495\n",
            "Epoch 54/100\n",
            "26/26 [==============================] - 9s 352ms/step - loss: 0.1447\n",
            "Epoch 55/100\n",
            "26/26 [==============================] - 9s 352ms/step - loss: 0.1440\n",
            "Epoch 56/100\n",
            "26/26 [==============================] - 9s 352ms/step - loss: 0.1396\n",
            "Epoch 57/100\n",
            "26/26 [==============================] - 9s 352ms/step - loss: 0.1383\n",
            "Epoch 58/100\n",
            "26/26 [==============================] - 9s 352ms/step - loss: 0.1960\n",
            "Epoch 59/100\n",
            "26/26 [==============================] - 9s 352ms/step - loss: 0.1546\n",
            "Epoch 60/100\n",
            "26/26 [==============================] - 9s 352ms/step - loss: 0.1401\n",
            "Epoch 61/100\n",
            "26/26 [==============================] - 9s 353ms/step - loss: 0.1345\n",
            "Epoch 62/100\n",
            "26/26 [==============================] - 9s 353ms/step - loss: 0.1346\n",
            "Epoch 63/100\n",
            "26/26 [==============================] - 9s 353ms/step - loss: 0.1327\n",
            "Epoch 64/100\n",
            "26/26 [==============================] - 9s 354ms/step - loss: 0.1293\n",
            "Epoch 65/100\n",
            "26/26 [==============================] - 9s 354ms/step - loss: 0.1278\n",
            "Epoch 66/100\n",
            "26/26 [==============================] - 9s 354ms/step - loss: 0.1285\n",
            "Epoch 67/100\n",
            "26/26 [==============================] - 9s 353ms/step - loss: 0.1277\n",
            "Epoch 68/100\n",
            "26/26 [==============================] - 11s 400ms/step - loss: 0.1251\n",
            "Epoch 69/100\n",
            "26/26 [==============================] - 9s 345ms/step - loss: 0.1239\n",
            "Epoch 70/100\n",
            "26/26 [==============================] - 9s 349ms/step - loss: 0.1241\n",
            "Epoch 71/100\n",
            "26/26 [==============================] - 9s 351ms/step - loss: 0.1223\n",
            "Epoch 72/100\n",
            "26/26 [==============================] - 9s 352ms/step - loss: 0.1217\n",
            "Epoch 73/100\n",
            "26/26 [==============================] - 9s 352ms/step - loss: 0.1338\n",
            "Epoch 74/100\n",
            "26/26 [==============================] - 9s 353ms/step - loss: 0.1309\n",
            "Epoch 75/100\n",
            "26/26 [==============================] - 9s 353ms/step - loss: 0.1198\n",
            "Epoch 76/100\n",
            "26/26 [==============================] - 9s 353ms/step - loss: 0.1164\n",
            "Epoch 77/100\n",
            "26/26 [==============================] - 9s 352ms/step - loss: 0.1158\n",
            "Epoch 78/100\n",
            "26/26 [==============================] - 9s 354ms/step - loss: 0.1155\n",
            "Epoch 79/100\n",
            "26/26 [==============================] - 9s 355ms/step - loss: 0.1170\n",
            "Epoch 80/100\n",
            "26/26 [==============================] - 9s 355ms/step - loss: 0.1135\n",
            "Epoch 81/100\n",
            "26/26 [==============================] - 9s 355ms/step - loss: 0.1144\n",
            "Epoch 82/100\n",
            "26/26 [==============================] - 9s 355ms/step - loss: 0.1116\n",
            "Epoch 83/100\n",
            "26/26 [==============================] - 9s 356ms/step - loss: 0.1140\n",
            "Epoch 84/100\n",
            "26/26 [==============================] - 9s 356ms/step - loss: 0.1142\n",
            "Epoch 85/100\n",
            "26/26 [==============================] - 11s 429ms/step - loss: 0.1116\n",
            "Epoch 86/100\n",
            "26/26 [==============================] - 9s 348ms/step - loss: 0.1105\n",
            "Epoch 87/100\n",
            "26/26 [==============================] - 9s 350ms/step - loss: 0.1122\n",
            "Epoch 88/100\n",
            "26/26 [==============================] - 9s 351ms/step - loss: 0.1109\n",
            "Epoch 89/100\n",
            "26/26 [==============================] - 9s 352ms/step - loss: 0.1101\n",
            "Epoch 90/100\n",
            "26/26 [==============================] - 9s 352ms/step - loss: 0.1103\n",
            "Epoch 91/100\n",
            "26/26 [==============================] - 9s 353ms/step - loss: 0.1096\n",
            "Epoch 92/100\n",
            "26/26 [==============================] - 9s 353ms/step - loss: 0.1108\n",
            "Epoch 93/100\n",
            "26/26 [==============================] - 9s 353ms/step - loss: 0.1087\n",
            "Epoch 94/100\n",
            "26/26 [==============================] - 9s 353ms/step - loss: 0.1075\n",
            "Epoch 95/100\n",
            "26/26 [==============================] - 9s 353ms/step - loss: 0.1069\n",
            "Epoch 96/100\n",
            "26/26 [==============================] - 9s 354ms/step - loss: 0.1064\n",
            "Epoch 97/100\n",
            "26/26 [==============================] - 9s 354ms/step - loss: 0.1068\n",
            "Epoch 98/100\n",
            "26/26 [==============================] - 9s 354ms/step - loss: 0.1055\n",
            "Epoch 99/100\n",
            "26/26 [==============================] - 9s 354ms/step - loss: 0.1066\n",
            "Epoch 100/100\n",
            "26/26 [==============================] - 9s 354ms/step - loss: 0.1161\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#предсказание модели\n",
        "example_batch_predictions = model(input_example_batch)\n",
        "print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0i-eBOTUuSt2",
        "outputId": "f864c7be-8d68-4e4e-f927-9e4f728d2e6e"
      },
      "execution_count": 324,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 91) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
      ],
      "metadata": {
        "id": "MRTNuwryuWMd"
      },
      "execution_count": 325,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
        "print()\n",
        "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e8wOSq5uYZS",
        "outputId": "d1067240-296e-45f7-b64b-6f43ffea6d75"
      },
      "execution_count": 326,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: \n",
            " 'Маршала и грубо заковывает в наручники.\\r\\nКВАРТИРА РОБИН - НОЧЬ\\r\\nТэд и Робин стоят у двери, прощаясь.'\n",
            "\n",
            "Next Char Predictions: \n",
            " 'сршале.и  рубо заковывает в наручники.\\r\\nКмАРТИРА РОБИН - НОЧЬ\\r\\nТэд и Робин стоят у двори, прощаясь.\\r'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Находим имя файла последней сохраненной контрольной точки\n",
        "tf.train.latest_checkpoint(checkpoint_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xYE8H2aP1odE",
        "outputId": "7db97d63-a18c-4dc5-f3b9-7598d3f08f0c"
      },
      "execution_count": 327,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Check/ckpt_85'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 327
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#строим модель\n",
        "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
        "\n",
        "#загружаем веса из последней сохраненной контрольной точки в модель\n",
        "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
        "\n",
        "model.build(tf.TensorShape([1, None]))"
      ],
      "metadata": {
        "id": "Zlwxl6Vo1vOh"
      },
      "execution_count": 328,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#информация о модели\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MK1Lf49iztDu",
        "outputId": "bc721d18-c2c0-473e-8653-aad6b017b3b9"
      },
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_20 (Embedding)    (1, None, 256)            23296     \n",
            "                                                                 \n",
            " lstm_73 (LSTM)              (1, None, 1024)           5246976   \n",
            "                                                                 \n",
            " lstm_74 (LSTM)              (1, None, 1024)           8392704   \n",
            "                                                                 \n",
            " lstm_75 (LSTM)              (1, None, 1024)           8392704   \n",
            "                                                                 \n",
            " lstm_76 (LSTM)              (1, None, 1024)           8392704   \n",
            "                                                                 \n",
            " dense_20 (Dense)            (1, None, 91)             93275     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 30,541,659\n",
            "Trainable params: 30,541,659\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, start_string):\n",
        "    # Этап оценки (генерация текста с использованием обученной модели)\n",
        "\n",
        "    # число букв для генераци\n",
        "    num_generate = 500\n",
        "\n",
        "    # Преобразование начальной строки в числа (векторизация)\n",
        "    input_eval = [char2idx[s] for s in start_string]\n",
        "    #Возвращаем тензор с осью длины 1, вставленной первой в индекс\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "\n",
        "    # Пустая строка для хранения результатов\n",
        "    text_generated = []\n",
        "\n",
        "    # Низкая температура приводит к более предсказуемому тексту.\n",
        "    # Более высокая температура приводит к более неожиданному тексту.\n",
        "    temperature = 0.001\n",
        "\n",
        "    # здесь batch size == 1\n",
        "    # сбрасываем состояния всех слоев в модели\n",
        "    model.reset_states()\n",
        "    for i in range(num_generate):\n",
        "        #получаем предсказания модели\n",
        "        predictions = model(input_eval)\n",
        "        #удаляем первую размерность в предсказании\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        # использование категориального распределения для прогнозирования символа, возвращаемого моделью\n",
        "        predictions = predictions / temperature\n",
        "        #извлекаем выборку из категориального распределения\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "\n",
        "        # Передаем предсказанный символ в качестве следующего ввода в модель\n",
        "        # вместе с предыдущим скрытым состоянием \n",
        "        # добавляем 1 первым индексом к размерности\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "        #сохраняем предсказанную букву\n",
        "        text_generated.append(idx2char[predicted_id])\n",
        "\n",
        "    return (start_string + ''.join(text_generated))"
      ],
      "metadata": {
        "id": "bnCgBvWfzuac"
      },
      "execution_count": 334,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_ = generate_text(model, start_string=u\"Привет, как дела? \")\n",
        "print(text_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pure6oZrzzmM",
        "outputId": "890adb53-c4ba-4d67-d68b-8d84a372c710"
      },
      "execution_count": 335,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Привет, как дела? Он смотрит, кто это\r\n",
            "и отвечает.\r\n",
            "                       БАРНИ\r\n",
            "             Эй, ты же знаешь, как я всегда\r\n",
            "             тащился от полуазиатских девчонок?\r\n",
            "СТОП-КАДР НА БАРНИ.\r\n",
            "                    РОБИН\r\n",
            "          Знаешь, думаю, мне нравится твоя\r\n",
            "          теория оливок в моем\r\n",
            "          холодильнике уже целую вечность\r\n",
            "          тусуется.\r\n",
            "                    ТЭД\r\n",
            "              (в шоке)\r\n",
            "          Ты ешь оливки?\r\n",
            "                    ТЭД\r\n",
            "              (пауза)\r\n",
            "          Ага, я никогда не пой\n"
          ]
        }
      ]
    }
  ]
}